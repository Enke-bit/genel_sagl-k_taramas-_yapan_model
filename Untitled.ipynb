{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80551cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age            0\n",
      "gender         0\n",
      "height         0\n",
      "weight         0\n",
      "ap_hi          0\n",
      "ap_lo          0\n",
      "cholesterol    0\n",
      "gluc           0\n",
      "smoke          0\n",
      "alco           0\n",
      "active         0\n",
      "cardio         0\n",
      "AgeinYr        0\n",
      "BMI            0\n",
      "BMICat         0\n",
      "AgeGroup       0\n",
      "dtype: int64\n",
      "Epoch 1/50\n",
      "5597/5597 [==============================] - 5s 903us/step - loss: 0.5583 - accuracy: 0.7266 - val_loss: 0.5482 - val_accuracy: 0.7293\n",
      "Epoch 2/50\n",
      "5597/5597 [==============================] - 5s 895us/step - loss: 0.5473 - accuracy: 0.7324 - val_loss: 0.5461 - val_accuracy: 0.7286\n",
      "Epoch 3/50\n",
      "5597/5597 [==============================] - 5s 899us/step - loss: 0.5446 - accuracy: 0.7334 - val_loss: 0.5432 - val_accuracy: 0.7314\n",
      "Epoch 4/50\n",
      "5597/5597 [==============================] - 5s 900us/step - loss: 0.5432 - accuracy: 0.7339 - val_loss: 0.5426 - val_accuracy: 0.7318\n",
      "Epoch 5/50\n",
      "5597/5597 [==============================] - 5s 904us/step - loss: 0.5423 - accuracy: 0.7348 - val_loss: 0.5423 - val_accuracy: 0.7326\n",
      "Epoch 6/50\n",
      "5597/5597 [==============================] - 5s 896us/step - loss: 0.5418 - accuracy: 0.7340 - val_loss: 0.5422 - val_accuracy: 0.7340\n",
      "Epoch 7/50\n",
      "5597/5597 [==============================] - 5s 884us/step - loss: 0.5409 - accuracy: 0.7350 - val_loss: 0.5411 - val_accuracy: 0.7348\n",
      "Epoch 8/50\n",
      "5597/5597 [==============================] - 5s 882us/step - loss: 0.5402 - accuracy: 0.7361 - val_loss: 0.5416 - val_accuracy: 0.7351\n",
      "Epoch 9/50\n",
      "5597/5597 [==============================] - 5s 898us/step - loss: 0.5399 - accuracy: 0.7359 - val_loss: 0.5415 - val_accuracy: 0.7342\n",
      "Epoch 10/50\n",
      "5597/5597 [==============================] - 5s 887us/step - loss: 0.5397 - accuracy: 0.7354 - val_loss: 0.5422 - val_accuracy: 0.7326\n",
      "Epoch 11/50\n",
      "5597/5597 [==============================] - 5s 885us/step - loss: 0.5395 - accuracy: 0.7346 - val_loss: 0.5414 - val_accuracy: 0.7320\n",
      "Epoch 12/50\n",
      "5597/5597 [==============================] - 5s 897us/step - loss: 0.5385 - accuracy: 0.7361 - val_loss: 0.5420 - val_accuracy: 0.7333\n",
      "Epoch 13/50\n",
      "5597/5597 [==============================] - 5s 898us/step - loss: 0.5384 - accuracy: 0.7370 - val_loss: 0.5441 - val_accuracy: 0.7339\n",
      "Epoch 14/50\n",
      "5597/5597 [==============================] - 5s 890us/step - loss: 0.5383 - accuracy: 0.7357 - val_loss: 0.5422 - val_accuracy: 0.7323\n",
      "Epoch 15/50\n",
      "5597/5597 [==============================] - 5s 896us/step - loss: 0.5377 - accuracy: 0.7363 - val_loss: 0.5422 - val_accuracy: 0.7353\n",
      "Epoch 16/50\n",
      "5597/5597 [==============================] - 5s 887us/step - loss: 0.5376 - accuracy: 0.7365 - val_loss: 0.5416 - val_accuracy: 0.7343\n",
      "Epoch 17/50\n",
      "5597/5597 [==============================] - 5s 883us/step - loss: 0.5375 - accuracy: 0.7368 - val_loss: 0.5415 - val_accuracy: 0.7343\n",
      "Epoch 18/50\n",
      "5597/5597 [==============================] - 5s 892us/step - loss: 0.5373 - accuracy: 0.7370 - val_loss: 0.5412 - val_accuracy: 0.7333\n",
      "Epoch 19/50\n",
      "5597/5597 [==============================] - 5s 894us/step - loss: 0.5370 - accuracy: 0.7382 - val_loss: 0.5461 - val_accuracy: 0.7340\n",
      "Epoch 20/50\n",
      "5597/5597 [==============================] - 5s 888us/step - loss: 0.5369 - accuracy: 0.7360 - val_loss: 0.5430 - val_accuracy: 0.7331\n",
      "Epoch 21/50\n",
      "5597/5597 [==============================] - 5s 888us/step - loss: 0.5365 - accuracy: 0.7379 - val_loss: 0.5433 - val_accuracy: 0.7334\n",
      "Epoch 22/50\n",
      "5597/5597 [==============================] - 5s 894us/step - loss: 0.5366 - accuracy: 0.7369 - val_loss: 0.5423 - val_accuracy: 0.7324\n",
      "Epoch 23/50\n",
      "5597/5597 [==============================] - 5s 889us/step - loss: 0.5362 - accuracy: 0.7384 - val_loss: 0.5441 - val_accuracy: 0.7308\n",
      "Epoch 24/50\n",
      "5597/5597 [==============================] - 5s 886us/step - loss: 0.5362 - accuracy: 0.7384 - val_loss: 0.5425 - val_accuracy: 0.7341\n",
      "Epoch 25/50\n",
      "5597/5597 [==============================] - 5s 887us/step - loss: 0.5358 - accuracy: 0.7381 - val_loss: 0.5429 - val_accuracy: 0.7326\n",
      "Epoch 26/50\n",
      "5597/5597 [==============================] - 5s 858us/step - loss: 0.5357 - accuracy: 0.7384 - val_loss: 0.5446 - val_accuracy: 0.7308\n",
      "Epoch 27/50\n",
      "5597/5597 [==============================] - 5s 875us/step - loss: 0.5357 - accuracy: 0.7377 - val_loss: 0.5422 - val_accuracy: 0.7340\n",
      "Epoch 28/50\n",
      "5597/5597 [==============================] - 5s 918us/step - loss: 0.5355 - accuracy: 0.7385 - val_loss: 0.5420 - val_accuracy: 0.7335\n",
      "Epoch 29/50\n",
      "5597/5597 [==============================] - 5s 888us/step - loss: 0.5353 - accuracy: 0.7388 - val_loss: 0.5434 - val_accuracy: 0.7314\n",
      "Epoch 30/50\n",
      "5597/5597 [==============================] - 5s 877us/step - loss: 0.5354 - accuracy: 0.7384 - val_loss: 0.5444 - val_accuracy: 0.7308\n",
      "Epoch 31/50\n",
      "5597/5597 [==============================] - 5s 909us/step - loss: 0.5351 - accuracy: 0.7382 - val_loss: 0.5444 - val_accuracy: 0.7308\n",
      "Epoch 32/50\n",
      "5597/5597 [==============================] - 5s 904us/step - loss: 0.5350 - accuracy: 0.7389 - val_loss: 0.5437 - val_accuracy: 0.7333\n",
      "Epoch 33/50\n",
      "5597/5597 [==============================] - 5s 900us/step - loss: 0.5349 - accuracy: 0.7383 - val_loss: 0.5425 - val_accuracy: 0.7330\n",
      "Epoch 34/50\n",
      "5597/5597 [==============================] - 5s 893us/step - loss: 0.5348 - accuracy: 0.7381 - val_loss: 0.5430 - val_accuracy: 0.7334\n",
      "Epoch 35/50\n",
      "5597/5597 [==============================] - 5s 903us/step - loss: 0.5348 - accuracy: 0.7380 - val_loss: 0.5437 - val_accuracy: 0.7338\n",
      "Epoch 36/50\n",
      "5597/5597 [==============================] - 5s 888us/step - loss: 0.5345 - accuracy: 0.7380 - val_loss: 0.5447 - val_accuracy: 0.7342\n",
      "Epoch 37/50\n",
      "5597/5597 [==============================] - 5s 893us/step - loss: 0.5345 - accuracy: 0.7379 - val_loss: 0.5438 - val_accuracy: 0.7335\n",
      "Epoch 38/50\n",
      "5597/5597 [==============================] - 5s 891us/step - loss: 0.5344 - accuracy: 0.7378 - val_loss: 0.5431 - val_accuracy: 0.7323\n",
      "Epoch 39/50\n",
      "5597/5597 [==============================] - 5s 887us/step - loss: 0.5342 - accuracy: 0.7389 - val_loss: 0.5442 - val_accuracy: 0.7317\n",
      "Epoch 40/50\n",
      "5597/5597 [==============================] - 5s 895us/step - loss: 0.5343 - accuracy: 0.7389 - val_loss: 0.5440 - val_accuracy: 0.7328\n",
      "Epoch 41/50\n",
      "5597/5597 [==============================] - 5s 910us/step - loss: 0.5339 - accuracy: 0.7375 - val_loss: 0.5446 - val_accuracy: 0.7321\n",
      "Epoch 42/50\n",
      "5597/5597 [==============================] - 5s 899us/step - loss: 0.5340 - accuracy: 0.7375 - val_loss: 0.5442 - val_accuracy: 0.7311\n",
      "Epoch 43/50\n",
      "5597/5597 [==============================] - 5s 868us/step - loss: 0.5338 - accuracy: 0.7386 - val_loss: 0.5450 - val_accuracy: 0.7322\n",
      "Epoch 44/50\n",
      "5597/5597 [==============================] - 5s 873us/step - loss: 0.5335 - accuracy: 0.7390 - val_loss: 0.5443 - val_accuracy: 0.7316\n",
      "Epoch 45/50\n",
      "5597/5597 [==============================] - 5s 892us/step - loss: 0.5337 - accuracy: 0.7380 - val_loss: 0.5451 - val_accuracy: 0.7331\n",
      "Epoch 46/50\n",
      "5597/5597 [==============================] - 5s 890us/step - loss: 0.5332 - accuracy: 0.7384 - val_loss: 0.5444 - val_accuracy: 0.7338\n",
      "Epoch 47/50\n",
      "5597/5597 [==============================] - 5s 898us/step - loss: 0.5335 - accuracy: 0.7392 - val_loss: 0.5439 - val_accuracy: 0.7312\n",
      "Epoch 48/50\n",
      "5597/5597 [==============================] - 5s 897us/step - loss: 0.5329 - accuracy: 0.7379 - val_loss: 0.5448 - val_accuracy: 0.7336\n",
      "Epoch 49/50\n",
      "5597/5597 [==============================] - 5s 890us/step - loss: 0.5329 - accuracy: 0.7395 - val_loss: 0.5436 - val_accuracy: 0.7308\n",
      "Epoch 50/50\n",
      "5597/5597 [==============================] - 5s 860us/step - loss: 0.5332 - accuracy: 0.7387 - val_loss: 0.5460 - val_accuracy: 0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\realb\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "# Veri setini yükle\n",
    "data = pd.read_csv(r'C:\\Users\\realb\\Desktop\\sağlık asistanı ai\\Health Screening Data.csv')\n",
    "\n",
    "# Gereksiz sütunları çıkarma\n",
    "data = data.drop(columns=['Unnamed: 0', 'id'])\n",
    "\n",
    "# Eksik verileri kontrol et\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Eksik verileri gerektiğinde doldur veya satırları çıkar\n",
    "data = data.dropna()\n",
    "\n",
    "# Kategorik verileri kodlama\n",
    "label_encoders = {}\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "# Özellik ve hedef değişkenleri ayırma\n",
    "target_column = 'cardio'  # Hedef sütununuzun adını burada belirtin\n",
    "X = data.drop(target_column, axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Veriyi normalize etme\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Veriyi Eğitim ve Test Setlerine Bölme\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Yapay Sinir Ağı modelini oluşturma\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Modeli derleme\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Modeli eğitme\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Modeli kaydetme\n",
    "model.save('health_assistant_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68b22eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023BB0C29F80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[0.1482192]]\n",
      "Tahmin yüzdesi: 14.821919798851013\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Modeli yükleme\n",
    "model = load_model(r'C:\\Users\\realb\\Desktop\\sağlık asistanı ai\\health_assistant_model.h5')\n",
    "\n",
    "# Kategorik verileri kodlamak için kullanılan LabelEncoder'ları ve scaler'ı yükleme\n",
    "label_encoders = {}  # Bu, eğitim sırasında kullanılan label encoder'ların yerini tutacak\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    label_encoders[column].fit(data[column])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data.drop('cardio', axis=1))\n",
    "\n",
    "# Yeni veriler üzerinde tahmin yapma fonksiyonu\n",
    "def predict_new_data(new_data):\n",
    "    # Yeni veriyi hazırlama\n",
    "    new_data_df = pd.DataFrame(new_data)\n",
    "    \n",
    "    # Kategorik verileri aynı LabelEncoder ile kodlama\n",
    "    for column, encoder in label_encoders.items():\n",
    "        if column in new_data_df.columns:\n",
    "            # Yeni verideki kategorik değerlerin eğitilen kodlar içinde olup olmadığını kontrol et\n",
    "            valid_labels = set(encoder.classes_)\n",
    "            new_data_df[column] = new_data_df[column].apply(lambda x: x if x in valid_labels else np.nan)\n",
    "            new_data_df[column] = encoder.transform(new_data_df[column].fillna(method='ffill'))\n",
    "    \n",
    "    # Eksik değerler varsa, bunları uygun şekilde işleme\n",
    "    new_data_df = new_data_df.fillna(-1)  # Burada eksik değerler için uygun bir dolgu yöntemi seçebilirsiniz\n",
    "    \n",
    "    # Veriyi normalize etme\n",
    "    new_data_scaled = scaler.transform(new_data_df)\n",
    "    \n",
    "    # Tahmin yapma\n",
    "    predictions = model.predict(new_data_scaled)\n",
    "    return predictions\n",
    "\n",
    "# Örnek yeni veri\n",
    "new_data = {\n",
    "    'age': [45],  # Yaş\n",
    "    'gender': [1],  # Cinsiyet\n",
    "    'height': [170],  # Boy\n",
    "    'weight': [70],  # Kilo\n",
    "    'ap_hi': [120],  # Sistolik kan basıncı\n",
    "    'ap_lo': [80],  # Diastolik kan basıncı\n",
    "    'cholesterol': [1],  # Kolesterol seviyesi\n",
    "    'gluc': [1],  # Glikoz seviyesi\n",
    "    'smoke': [0],  # Sigara kullanımı\n",
    "    'alco': [0],  # Alkol kullanımı\n",
    "    'active': [1],  # Fiziksel aktivite\n",
    "    'AgeinYr': [45],  # Yaş (yıl olarak)\n",
    "    'BMI': [24.2],  # Vücut kitle indeksi\n",
    "    'BMICat': [1],  # BMI kategorisi\n",
    "    'AgeGroup': [2]  # Yaş grubu\n",
    "}\n",
    "\n",
    "# Tahmin yapma\n",
    "predictions = predict_new_data(new_data)\n",
    "print(predictions)\n",
    "\n",
    "tahmin_yuzdesi = predictions[0][0] * 100\n",
    "print(\"Tahmin yüzdesi:\", tahmin_yuzdesi)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
